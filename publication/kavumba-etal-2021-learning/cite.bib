@inproceedings{kavumba-etal-2021-learning,
 abstract = {Improving model generalization on held-out data is one of the core objectives in common- sense reasoning. Recent work has shown that models trained on the dataset with superficial cues tend to perform well on the easy test set with superficial cues but perform poorly on the hard test set without superficial cues. Previous approaches have resorted to manual methods of encouraging models not to overfit to superficial cues. While some of the methods have improved performance on hard instances, they also lead to degraded performance on easy in- stances. Here, we propose to explicitly learn a model that does well on both the easy test set with superficial cues and the hard test set without superficial cues. Using a meta-learning objective, we learn such a model that improves performance on both the easy test set and the hard test set. By evaluating our models on Choice of Plausible Alternatives (COPA) and Commonsense Explanation, we show that our proposed method leads to improved performance on both the easy test set and the hard test set upon which we observe up to 16.5 percentage points improvement over the baseline.},
 address = {Online},
 author = {Kavumba, Pride  and
Heinzerling, Benjamin  and
Brassard, Ana  and
Inui, Kentaro},
 booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
 doi = {10.18653/v1/2021.naacl-main.304},
 month = {June},
 pages = {3890--3898},
 publisher = {Association for Computational Linguistics},
 title = {Learning to Learn to be Right for the Right Reasons},
 url = {https://aclanthology.org/2021.naacl-main.304},
 year = {2021}
}

